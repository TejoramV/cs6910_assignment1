{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPrdYiS0Gp5"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# CS6910 Assignment-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSt87eAa0Gp6"
      },
      "source": [
        "by\n",
        "- Akansh Maurya (CS22Z003)\n",
        "- Tejoram Vivekanandan (EE22Z001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-vPuna71_pW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7LJZ8YRg13tG",
        "outputId": "cf4c7825-9175-40c7-cebf-50557ddac165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.6-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=afdf1d3545c511b03400bd7a97952fdd8958098824d92e333dde9c4b6cf021d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.6 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.10 yaspin-2.1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "Aborted!\n",
            "^C\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb_setup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Make sure we have a logger setup (might be an early logger)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mwl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbSetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0m_WandbSetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbSetup__WandbSetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, settings, environ, pid)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_early_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m# self._settings.freeze()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_settings_setup\u001b[0;34m(self, settings, early_logger)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_settings_from_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cli_only_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36minfer_settings_from_environment\u001b[0;34m(self, _logger)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_jupyter_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mnotebook_metadata\u001b[0;34m(silent)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# In colab we can request the most recent contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mipynb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_colab_load_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_load_ipynb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# This isn't thread safe, never call in a thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0e90def6f631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wandb login'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CS6910-Assignment-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"akansh12\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "wandb.init(project=\"CS6910-Assignment-1\", entity=\"akansh12\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUZstREBMqW1"
      },
      "source": [
        "### Question 1: Loading and ploting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk9LKi51h2ef",
        "outputId": "0fe452d7-bc2b-4c2c-fb9b-9f03b2b26d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "dataset= fashion_mnist.load_data()\n",
        "(X_train_and_validation, y_train_and_validation), (X_test, y_test) = dataset\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train_and_validation, y_train_and_validation, test_size=0.1, random_state=42)\n",
        "X_train = (X_train/255.0).astype(np.float32)\n",
        "X_validation = (X_validation/255.0).astype(np.float32)\n",
        "X_test = (X_test/255.0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rKJqmeEDGiF"
      },
      "outputs": [],
      "source": [
        "labels_dict =  {0:\t\"T-shirt/top\",\n",
        "1 :\"Trouser\",\n",
        "2 :\"Pullover\",\n",
        "3:\t\"Dress\",\n",
        "4 :\"Coat\",\n",
        "5 :\"Sandal\",\n",
        "6 :\"Shirt\",\n",
        "7 :\"Sneaker\",\n",
        "8 :\"Bag\",\n",
        "9 :\"Ankle boot\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLZWiHVUkL05",
        "outputId": "d64a1f3d-c252-4dce-8484-9c6136c109f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset Shape:  (54000, 28, 28)\n",
            "Train Target Vector Shape:  (54000,)\n",
            "Test Dataset Shape: (10000, 28, 28)\n",
            "Test Target Vector Shape (10000,)\n",
            "Validation Dataset Shape: (6000, 28, 28)\n",
            "Validation Target Vector Shape (6000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Dataset Shape: \", X_train.shape)\n",
        "print(\"Train Target Vector Shape: \", y_train.shape) \n",
        "print(\"Test Dataset Shape:\", X_test.shape)\n",
        "print(\"Test Target Vector Shape\", y_test.shape)\n",
        "print(\"Validation Dataset Shape:\", X_validation.shape)\n",
        "print(\"Validation Target Vector Shape\", y_validation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"CS6910-Assignment-1\", entity=\"akansh12\")\n",
        "sorted_arr = [-1] * 10\n",
        "step_count=0\n",
        "steps_needed=5                                  ###increase the step as per the need, currently it is restricted to 5 for better user iterface\n",
        "while(step_count<steps_needed):\n",
        "  for x in range(10):\n",
        "    boolean = 0\n",
        "    sample = sorted_arr[x]+1\n",
        "    while(boolean == 0):\n",
        "      if x == y_train[sample]:\n",
        "        boolean = 1\n",
        "        sorted_arr[x]=sample\n",
        "      sample=sample+1\n",
        "  step_count= step_count+1  \n",
        "  %matplotlib inline\n",
        "  fig, axes = plt.subplots(2,5, figsize = (15,8))\n",
        "  for i in range(10):\n",
        "     ax = axes[i//5, i%5]\n",
        "     x=sorted_arr[i]\n",
        "     ax.imshow(X_train[x], cmap='gray')\n",
        "     ax.set_title(f'{labels_dict[y_train[x]]}')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  wandb.log({\"Data-plot\": fig})\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "KJ5uXBWIGHQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgV1JgmlNcbx"
      },
      "source": [
        "**Implement a feedforward and backpropagation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfvF6d_bNawA"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5kuEsnVZQ6e"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WdFI5xebOk-"
      },
      "outputs": [],
      "source": [
        "class DeepNeuralNetwork():\n",
        "  def __init__(self,epochs,num_input_nodes, hidden_layers,num_output_nodes, lr, weight_decay, optimizer, batch_size, w_initial, activation_function = 'sigmoid', loss_type = 'cross_entropy'):\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr \n",
        "    self.weight_decay = weight_decay\n",
        "    self.optimizer = optimizer\n",
        "    self.optimizer.lr = self.lr      \n",
        "    self.batch_size = batch_size\n",
        "    self.num_input_nodes = num_input_nodes\n",
        "    self.hidden_layers = hidden_layers\n",
        "    self.num_output_nodes = num_output_nodes\n",
        "    self.loss_type = loss_type\n",
        "    #Activation function\n",
        "    self.activation_function = self.activation(activation_function)\n",
        "\n",
        "    #parameter initialization\n",
        "    self.params = self.initialization(weight_initialisation = w_initial)\n",
        "\n",
        "\n",
        "  def initialization(self, weight_initialisation = 'random'):\n",
        "    w = []\n",
        "    b = []\n",
        "\n",
        "    if weight_initialisation == 'random':\n",
        "      w.append(np.random.randn(self.hidden_layers[0],self.num_input_nodes)*0.01)\n",
        "    elif weight_initialisation == 'Xavier':\n",
        "      w.append(np.random.randn(self.hidden_layers[0],self.num_input_nodes)*np.sqrt(2/(self.num_input_nodes+self.hidden_layers[0])))\n",
        "    b.append(np.random.randn(self.hidden_layers[0],1)*0.01)\n",
        "\n",
        "    for i in range(1,len(self.hidden_layers)):\n",
        "      if weight_initialisation == 'random':\n",
        "        w.append(np.random.randn(self.hidden_layers[i],self.hidden_layers[i-1])*0.01)\n",
        "      elif weight_initialisation == 'Xavier':\n",
        "        w.append(np.random.randn(self.hidden_layers[i],self.hidden_layers[i-1])*np.sqrt(2/(self.hidden_layers[i-1]+self.hidden_layers[i])))\n",
        "      b.append(np.random.randn(self.hidden_layers[i],1)*0.01)\n",
        "\n",
        "    if weight_initialisation == 'random':\n",
        "      w.append(np.random.randn(self.num_output_nodes,self.hidden_layers[len(self.hidden_layers)-1])*0.01)\n",
        "    elif weight_initialisation == 'Xavier':\n",
        "      w.append(np.random.randn(self.num_output_nodes,self.hidden_layers[len(self.hidden_layers)-1])*np.sqrt(2/(self.hidden_layers[len(self.hidden_layers)-1] + self.num_output_nodes)))\n",
        "    b.append(np.random.randn(self.num_output_nodes,1)*0.01)\n",
        "\n",
        "    return {'w':w, 'b':b}\n",
        "\n",
        "  def activation(self, activation_function):\n",
        "\n",
        "    if activation_function == 'sigmoid':\n",
        "      return self.sigmoid\n",
        "    if activation_function == 'tanh':\n",
        "      return self.tanh\n",
        "    if activation_function == 'ReLU':\n",
        "      return self.relu\n",
        "\n",
        "  def sigmoid(self,x, derivative = False):\n",
        "    if derivative:\n",
        "      return self.sigmoid(x)*(1-self.sigmoid(x))\n",
        "    return 1/(1 + np.exp(-x))  \n",
        "\n",
        "  def tanh(self, x, derivative = False):\n",
        "    if derivative:\n",
        "      return 1 - self.tanh(x)**2\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "  def relu(self, x, derivative = False):\n",
        "    if derivative:\n",
        "      return (x>0)*1 \n",
        "    return x*(x>0)\n",
        "\n",
        "  def softmax(self,x,derivative = False):\n",
        "    if derivative:\n",
        "      return self.softmax(x)*(1- self.softmax(x))\n",
        "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
        "\n",
        "  def one_hot(self,y):\n",
        "    v = np.zeros((self.num_output_nodes, len(y)))\n",
        "    for i,j in enumerate(y):\n",
        "      v[j,i] = 1\n",
        "    return v\n",
        "\n",
        "  def compute_accuracy(self, x_val, y_val):\n",
        "\n",
        "    x_val = x_val.reshape(self.num_input_nodes, -1)\n",
        "\n",
        "    out = self.feed_forward(x_val)\n",
        "    pred = np.argmax(out, axis = 0)\n",
        "\n",
        "    return np.mean(pred == y_val)*100\n",
        "\n",
        "\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    if self.loss_type == 'cross_entropy':\n",
        "      return -1*np.sum(np.multiply(self.one_hot(y_true), np.log(y_pred)))\n",
        "    if self.loss_type == 'mean_square_error':\n",
        "      return np.sum((self.one_hot(y_true) - y_pred) ** 2)*0.5\n",
        "\n",
        "  def feed_forward(self, x):\n",
        "    #a=wh+b\n",
        "    #h=activation function(a)\n",
        "    self.a = []\n",
        "    self.h = []\n",
        "    self.a.append(np.dot(self.params['w'][0], x) + self.params['b'][0])\n",
        "    self.h.append(self.activation_function(self.a[0]))\n",
        "\n",
        "    for i in range(1, len(self.hidden_layers)):\n",
        "      self.a.append(np.dot(self.params['w'][i], self.h[i-1])+ self.params['b'][i])\n",
        "      self.h.append(self.activation_function(self.a[i]))\n",
        "\n",
        "    self.a.append(np.dot(self.params['w'][len(self.hidden_layers)],self.h[len(self.hidden_layers)-1])+self.params['b'][len(self.hidden_layers)])\n",
        "\n",
        "    out = self.softmax(self.a[len(self.hidden_layers)])\n",
        "    return out\n",
        "\n",
        "  def back_propagation(self,x, y_train,y_train_prob):\n",
        "    self.ga= [0]*(len(self.a))\n",
        "    self.gh= [0]*(len(self.h)) \n",
        "    self.gW= [0]*(len(self.params['w']))\n",
        "    self.gB= [0]*(len(self.params['b']))\n",
        "\n",
        "    if self.loss_type == 'cross_entropy':\n",
        "      self.ga[len(self.hidden_layers)]= -1*(self.one_hot(y_train)-y_train_prob)\n",
        "\n",
        "    if self.loss_type== 'mean_square_error': \n",
        "      self.ga[len(self.hidden_layers)]= (self.one_hot(y_train)-y_train_prob)*self.one_hot(y_train)*(1 - self.one_hot(y_train))  ## Check this\n",
        "\n",
        "    for i in range(len(self.hidden_layers), 0,-1):\n",
        "      self.gW[i] = np.dot(self.ga[i], self.h[i-1].T)\n",
        "      self.gB[i] = np.dot(self.ga[i], np.ones((self.batch_size, 1)))\n",
        "\n",
        "      self.gh[i-1] = np.dot(self.params['w'][i].T, self.ga[i])\n",
        "      self.ga[i-1] = np.multiply(self.gh[i-1], self.activation_function(self.a[i-1], derivative = True))  ### Check this\n",
        "    \n",
        "    self.gW[0] = np.dot(self.ga[0], x.T)\n",
        "    self.gB[0] = np.dot(self.ga[0], np.ones((self.batch_size, 1)))\n",
        "\n",
        "    return self.gW, self.gB\n",
        "\n",
        "  def train(self, x_train, y_train, x_val, y_val):\n",
        "    N = x_train.shape[0]\n",
        "    n_batches = int(np.floor(N / self.batch_size))\n",
        "    for epoch in range(0, self.epochs):\n",
        "\n",
        "      #data shuffle\n",
        "      # shuffler = np.random.permutation(len(x_train))\n",
        "      # x_train = x_train[shuffler]\n",
        "      # y_train = y_train[shuffler]\n",
        "\n",
        "      l = 0\n",
        "      for batch in tqdm(range(0, n_batches)):\n",
        "        x = x_train[batch*self.batch_size:self.batch_size+batch*self.batch_size].reshape(self.num_input_nodes,self.batch_size)\n",
        "        y = y_train[batch*self.batch_size:self.batch_size+batch*self.batch_size]\n",
        "        out = self.feed_forward(x)\n",
        "        gW, gB = self.back_propagation(x, y, out)\n",
        "        self.params = self.optimizer.update(self.params, gW,gB)\n",
        "        l += self.loss(out, y)\n",
        "\n",
        "      try:\n",
        "        x = x_train[-1*N%n_batches:].reshape(self.num_input_nodes,N%n_batches)\n",
        "        y = y_train[-1*N%n_batches:]\n",
        "        out = self.feed_forward(x)\n",
        "        gW, gB = self.back_propagation(x, y, out)\n",
        "        self.params = self.optimizer.update(self.params, gW,gB)\n",
        "        l += self.loss(out, y)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      print(f\"Epoch: {epoch}, loss: {l/N}\")\n",
        "      print(f\"Accuracy: {self.compute_accuracy(x_val, y_val)}\")\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizing functions**"
      ],
      "metadata": {
        "id": "5LcMwwu4JS-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "recqY3V8L1Uk"
      },
      "outputs": [],
      "source": [
        "class SGD:\n",
        "\n",
        "  ''' Stochastic Gradient Descent '''\n",
        "  def __init__(self, lr = 0.001):\n",
        "    self.lr = lr\n",
        "  \n",
        "\n",
        "  def update(self, params, gW, gB):\n",
        "    W = np.array(params['w'], dtype = object)\n",
        "    B = np.array(params['b'], dtype = object)\n",
        "\n",
        "    W -= self.lr * np.array(gW, dtype = object)\n",
        "    B -= self.lr * np.array(gB, dtype = object)\n",
        "\n",
        "    return {'w':W.tolist(), 'b': B.tolist()}\n",
        "\n",
        "class Momentum:\n",
        "\n",
        "  def __init__(self, lr = 0.001, gamma = 0.9):\n",
        "    self.lr = lr\n",
        "    self.gamma = gamma\n",
        "    self.Wmoments = None\n",
        "    self.Bmoments = None\n",
        "\n",
        "  def update(self, params, gW, gB):\n",
        "    if self.Wmoments == None:\n",
        "      self.Wmoments = [0] * len(params['w'])\n",
        "      for i in range(len(params['w'])):\n",
        "        self.Wmoments[i] = np.zeros_like(params['w'][i])\n",
        "\n",
        "    if self.Bmoments == None:\n",
        "      self.Bmoments = [0] * len(params['b'])\n",
        "      for i in range(len(params['b'])):\n",
        "        self.Bmoments[i] = np.zeros_like(params['b'][i])\n",
        "    \n",
        "    self.Wmoments = self.gamma * np.array(self.Wmoments, dtype = object) + self.lr * np.array(gW, dtype = object)\n",
        "    W = np.array(params['w'], dtype = object) - self.Wmoments\n",
        "    self.Wmoments = self.Wmoments.tolist()\n",
        "\n",
        "    self.Bmoments = self.gamma * np.array(self.Bmoments, dtype = object) + self.lr * np.array(gB, dtype = object)\n",
        "    B = np.array(params['b'], dtype = object) - self.Bmoments\n",
        "    self.Bmoments = self.Bmoments.tolist()\n",
        "    \n",
        "    return {'w':W.tolist(), 'b': B.tolist()}\n",
        "\n",
        "class Nesterov:\n",
        "  def __init__(self, model, x_train, y_train, lr=0.01, gamma=0.9):\n",
        "    self.lr = lr\n",
        "    self.gamma = gamma\n",
        "    self.model = model\n",
        "    self.x = x_train\n",
        "    self.y = y_train\n",
        "    self.Wmoments = None\n",
        "    self.Bmoments = None\n",
        "        \n",
        "  def update(self, params, gW, gB):\n",
        "    if self.Wmoments == None:\n",
        "      self.Wmoments = [0] * len(params['w'])\n",
        "      for i in range(len(params['w'])):\n",
        "        self.Wmoments[i] = np.zeros_like(params['w'][i])\n",
        "\n",
        "    if self.Bmoments == None:\n",
        "      self.Bmoments = [0] * len(params['b'])\n",
        "      for i in range(len(params['b'])):\n",
        "        self.Bmoments[i] = np.zeros_like(params['b'][i])\n",
        "\n",
        "\n",
        "    W_look_ahead = np.array(params['w'], dtype = object) - self.gamma*np.array(self.Wmoments, dtype = object)\n",
        "    B_look_ahead = np.array(params['b'], dtype = object) - self.gamma*np.array(self.Bmoments, dtype = object)\n",
        "    ###\n",
        "    self.model.params['w'] = W_look_ahead.tolist()\n",
        "    self.model.params['b'] = B_look_ahead.tolist()\n",
        "    out = self.model.feed_forward(self.x)\n",
        "    gW_look_ahead, gB_look_ahead = self.model.back_propagation(self.x, self.y, out)\n",
        "\n",
        "    ###\n",
        "    self.Wmoments = self.gamma*np.array(self.Wmoments, dtype = object) + self.lr * np.array(gW_look_ahead, dtype = object)\n",
        "    self.Bmoments = self.gamma*np.array(self.Bmoments, dtype = object) + self.lr * np.array(gB_look_ahead, dtype = object)\n",
        "\n",
        "    W = np.array(params['w'], dtype = object) - self.Wmoments\n",
        "    self.Wmoments = self.Wmoments.tolist()\n",
        "\n",
        "    B = np.array(params['b'], dtype = object) - self.Bmoments\n",
        "    self.Bmoments = self.Bmoments.tolist()\n",
        "\n",
        "    return {'w':W.tolist(), 'b': B.tolist()}\n",
        "\n",
        "class AdaGrad:\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "    self.vW = None\n",
        "    self.vB = None\n",
        "      \n",
        "  def update(self, params, gW, gB):\n",
        "    if self.vW == None:\n",
        "      self.vW = [0] * len(params['w'])\n",
        "      for i in range(len(params['w'])):\n",
        "          self.vW[i] = np.zeros_like(params['w'][i])\n",
        "\n",
        "    if self.vB == None:\n",
        "      self.vB = [0] * len(params['b'])\n",
        "      for i in range(len(params['b'])):\n",
        "          self.vB[i] = np.zeros_like(params['b'][i])\n",
        "\n",
        "    self.vW = np.array(self.vW, dtype = object) + np.array(gW, dtype = object) **2 \n",
        "    W = np.array(params['w'], dtype = object) - (self.lr/(np.sqrt(self.vW + 1e-7))) * np.array(gW, dtype = object)\n",
        "    self.vW = self.vW.tolist()\n",
        "\n",
        "    self.vB = np.array(self.vB, dtype = object) + np.array(gB, dtype = object) **2 \n",
        "    B = np.array(params['b'], dtype = object) - (self.lr/(np.sqrt(self.vB + 1e-7))) * np.array(gB, dtype = object)\n",
        "    self.vB = self.vB.tolist()\n",
        "\n",
        "    return {'w':W.tolist(), 'b': B.tolist()}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RMSprop:\n",
        "  def __init__(self, lr=0.01, beta = 0.99):\n",
        "    self.lr = lr\n",
        "    self.vW = None\n",
        "    self.vB = None\n",
        "    self.beta = beta\n",
        "\n",
        "  def update(self, params, gW, gB):\n",
        "    if self.vW == None:\n",
        "      self.vW = [0] * len(params['w'])\n",
        "      for i in range(len(params['w'])):\n",
        "        self.vW[i] = np.zeros_like(params['w'][i])\n",
        "\n",
        "    if self.vB == None:\n",
        "      self.vB = [0] * len(params['b'])\n",
        "      for i in range(len(params['b'])):\n",
        "        self.vB[i] = np.zeros_like(params['b'][i])\n",
        "\n",
        "    self.vW = self.beta*np.array(self.vW, dtype = object) + (1-self.beta)*(np.array(gW, dtype = object) **2) \n",
        "    W = np.array(params['w'], dtype = object) - (self.lr/(np.sqrt(self.vW + 1e-7))) * np.array(gW, dtype = object)\n",
        "    self.vW = self.vW.tolist()\n",
        "\n",
        "    self.vB = self.beta*np.array(self.vB, dtype = object) + (1-self.beta)*(np.array(gB, dtype = object) **2 )\n",
        "    B = np.array(params['b'], dtype = object) - (self.lr/(np.sqrt(self.vB + 1e-7))) * np.array(gB, dtype = object)\n",
        "    self.vB = self.vB.tolist()\n",
        "\n",
        "    return {'w':W.tolist(), 'b': B.tolist()}\n",
        "            \n",
        "        \n",
        "class Adam:\n",
        "  def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "    self.lr = lr\n",
        "    self.beta1 = beta1\n",
        "    self.beta2 = beta2\n",
        "    self.t = 0\n",
        "    self.mW = None\n",
        "    self.vW = None\n",
        "    self.mB = None\n",
        "    self.vB = None\n",
        "        \n",
        "  def update(self, params, gW, gB):\n",
        "\n",
        "    if self.mW is None:\n",
        "      self.mW, self.vW = [0] * len(params['w']), [0] * len(params['w'])\n",
        "      for i in range(len(params['w'])):\n",
        "        self.mW[i] = np.zeros_like(params['w'][i])\n",
        "        self.vW[i] = np.zeros_like(params['w'][i])\n",
        "\n",
        "    if self.mB is None:\n",
        "      self.mB, self.vB = [0] * len(params['b']), [0] * len(params['b'])\n",
        "      for i in range(len(params['b'])):\n",
        "        self.mB[i] = np.zeros_like(params['b'][i])\n",
        "        self.vB[i] = np.zeros_like(params['b'][i])\n",
        "    \n",
        "\n",
        "    self.t += 1\n",
        "\n",
        "    self.mW = (self.beta1 * np.array(self.mW, dtype = object)) + (1-self.beta1)*(np.array(gW, dtype = object))\n",
        "    self.vW = (self.beta2 * np.array(self.vW, dtype = object)) + (1-self.beta2)*(np.array(gW, dtype = object)**2)\n",
        "\n",
        "    self.mB = (self.beta1 * np.array(self.mB, dtype = object)) + (1-self.beta1)*(np.array(gB, dtype = object))\n",
        "    self.vB = (self.beta2 * np.array(self.vB, dtype = object)) + (1-self.beta2)*(np.array(gB, dtype = object)**2)\n",
        "\n",
        "    # Bias Correction\n",
        "    self.mW = (self.mW)*(1.0/(1-self.beta1**self.t))\n",
        "    self.vW = (self.vW)*(1.0/(1-self.beta2**self.t))\n",
        "    self.mB = (self.mB)*(1.0/(1-self.beta1**self.t))\n",
        "    self.vB = (self.vB)*(1.0/(1-self.beta2**self.t))\n",
        "\n",
        "    W = np.array(params['w'], dtype = object) - (self.lr/(np.sqrt(self.vW + 1e-7))) * self.mW\n",
        "    self.vW = self.vW.tolist()\n",
        "    self.mW = self.mW.tolist()\n",
        "\n",
        "    B = np.array(params['b'], dtype = object) - (self.lr/(np.sqrt(self.vB + 1e-7))) * self.mB\n",
        "    self.vB = self.vB.tolist()\n",
        "    self.mB = self.mB.tolist()\n",
        "\n",
        "    return {'w':W.tolist(), 'b': B.tolist()} \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6vFLxpqF55F"
      },
      "outputs": [],
      "source": [
        "model = DeepNeuralNetwork(epochs = 5,num_input_nodes = 784, hidden_layers = [1024, 512, 256],num_output_nodes = 10, lr = 0.001, weight_decay = None, optimizer = SGD(), batch_size= 16, w_initial = 'Xavier', activation_function = 'sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrCPH-4sF55G"
      },
      "outputs": [],
      "source": [
        "mean = np.mean(X_train)\n",
        "std = np.std(X_train)\n",
        "X_train = (X_train - mean )/ std\n",
        "X_validation = (X_validation - mean )/ std "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saVLXwkVF55G"
      },
      "outputs": [],
      "source": [
        "model.train(X_train, y_train, X_validation, y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Xfv158ZWWJ"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"CS6910-Assignment-1\", entity=\"akansh12\") ##change login\n",
        "print(y_train[54000-50:54000].shape) ### I have implemeted for batch size of 50 change this index (and forecoming) for whole date ..also Y sd be from whole data\n",
        "\n",
        "labels_dict_names =  [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "\n",
        "\n",
        "Y_prediction=np.empty(np.shape(y_train[54000-50:54000])) ##index change\n",
        "print(len(Y_prediction))\n",
        "for i in range(len(Y_prediction)):\n",
        "  Y_prediction[i]=np.argmax(Y[:,i])\n",
        "\n",
        "wandb.log({\"Confusion matrix\": wandb.plot.confusion_matrix(probs=None,y_true=y_train[54000-50:54000],preds=Y_prediction,class_names=labels_dict_names)}) ##index change"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}